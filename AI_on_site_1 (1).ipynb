{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI on site 1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gi7hfwgaihe"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpnh4ds6bden"
      },
      "source": [
        "import keras\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVtIVGlzbowy"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rg-Y7lCcW6i"
      },
      "source": [
        "x = np.array([1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0],dtype=float)\n",
        "y = np.array([3.0,6.0,9.0,12.0,15.0,18.0,21.0,24.0,27.0,30.0], dtype=float)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlQwz0Cccna6"
      },
      "source": [
        "model = keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em-zNeahXB3F"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdrF53JpVfte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d310085-e1d1-4e21-bf1a-2a7f9dc010b9"
      },
      "source": [
        "model.fit(x, y,epochs=100)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0246\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0244\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0242\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0240\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0238\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0236\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0234\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0232\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0230\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0228\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0226\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0224\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0222\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0220\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0218\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0217\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0215\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0213\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0211\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0209\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0208\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0206\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0204\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0202\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0201\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0199\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0197\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0196\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0194\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0192\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0191\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0189\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0188\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0186\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0185\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0183\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0181\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0180\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0178\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0177\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0175\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0174\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0172\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0171\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0170\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0168\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0167\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0165\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0164\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0163\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0161\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0160\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0159\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0157\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0156\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0155\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0153\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0152\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0151\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0150\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0148\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0147\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0146\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0145\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0143\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0142\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0141\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0140\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0139\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0137\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0136\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0135\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0134\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0133\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0132\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0131\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0130\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0127\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0126\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0125\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0124\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0123\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0122\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0121\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0120\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0119\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0118\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0117\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0116\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0115\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0114\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0113\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0112\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0111\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0110\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0109\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0109\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0108\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0107\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc132ca2910>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnHoM7QFW9rc",
        "outputId": "cd8b38e1-99e4-4500-d206-28c0292e218d"
      },
      "source": [
        "model.predict([2])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.1584115]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bEWjd_aXnBh"
      },
      "source": [
        "from keras.datasets import mnist"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgEUqVvclfjU",
        "outputId": "03e75ed2-44da-4472-9696-90190734d504"
      },
      "source": [
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSr6K0NylveM",
        "outputId": "289ee96c-abeb-4f54-ebd9-431582b55b8a"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_90_GPalx47"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLfhqSmvnIjR"
      },
      "source": [
        "network = models.Sequential()\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJEs_1GMoR3X"
      },
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cAlr32gowYR"
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRCHD10to7YI",
        "outputId": "e449c13f-6739-4b8b-9e0d-c4aea3051b0b"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K98PmF8apzIw"
      },
      "source": [
        "train_images = train_images.astype('float32') / 255"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsTM4oC-qqOn",
        "outputId": "df6e8fa6-1c24-435e-f639-703ac7b437fc"
      },
      "source": [
        "train_images[0]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
              "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
              "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
              "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
              "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
              "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
              "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
              "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
              "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
              "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
              "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
              "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
              "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
              "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
              "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
              "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
              "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
              "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
              "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
              "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
              "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAD-b5Sequkh"
      },
      "source": [
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_UE9eZvr2Q0",
        "outputId": "c8917812-6ad1-4431-af1c-97612f5a329b"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPnUcugMq49R"
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USeUqxslr7oJ"
      },
      "source": [
        "train_labels = np_utils.to_categorical(train_labels)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh-P9YAisVH4",
        "outputId": "c9842b6b-aae7-4fe3-b861-5572afd1ad29"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NvRs3s_sZCv"
      },
      "source": [
        "test_labels = np_utils.to_categorical(test_labels)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0rccgQTshqv",
        "outputId": "7869700a-0283-4831-c956-835e8adbdb1a"
      },
      "source": [
        "network.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0317 - accuracy: 0.9921\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0252 - accuracy: 0.9932\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0201 - accuracy: 0.9946\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0174 - accuracy: 0.9955\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0136 - accuracy: 0.9962\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc1281ea910>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WROxKFOIsupn",
        "outputId": "127e6d61-7a98-4772-b4e5-1e61e2449665"
      },
      "source": [
        "network.evaluate(test_images, test_labels)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0963292196393013, 0.9822999835014343]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxg0MyWYtqnF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}